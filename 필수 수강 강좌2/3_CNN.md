# CNN

: 이제까지 MLP는 각 뉴런들이 선형모델과 활성함수로 모두 연결된(fully connected) 구조

: 그러나 convolution 연산은 kernel을 움직여가며 선형모델과 합성함수가 적용되는 구조



### 연산 이해

g(x): 신호, kernel



### 다양한 차원에서의 convolution

: 다양한 차원에서 계산 가능



### 2차원 convolution 연산 이해하기

: 벡터에서 움직여가면서 합성함수 적용

: 이때 행렬 곱이 아닌 성분 곱을 통해 스칼라값을 받음 (parameter 계산과는 별도네...알아두기!)

: 출력크기도 이해하기

: 커널이 여러개인 경우 각각의 입력에 적용한다고 생각하면 됨



### convolution 연산 역전파

: 역전파를 계산할 떄도 convolution 연산이 나오게 됨

: 이거는 이해 안되면 나중에 강의 다시 보기



